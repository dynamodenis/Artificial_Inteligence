{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dynamodenis/Artificial_Inteligence/blob/main/A3C_for_Kung_Fu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A3C for Kung Fu"
      ],
      "metadata": {
        "id": "dIo6Zkp7U1Hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0 - Installing the required packages and importing the libraries"
      ],
      "metadata": {
        "id": "pz8ogVxGVB6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Gymnasium"
      ],
      "metadata": {
        "id": "CqN2IEX1VKzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbnq3XpoKa_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e885e218-1567-47b2-fe55-bdc3a4076413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "\u001b[33mWARNING: gymnasium 1.2.1 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.12/dist-packages (from ale-py) (2.0.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (881 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Downloading swig-4.3.1.post0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.1.post0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp312-cp312-linux_x86_64.whl size=2381958 sha256=1114941eeedd353939d62b2de7757f0b85cfc2185f80d9f95db94de60aa5bdb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/e9/60/774da0bcd07f7dc7761a8590fa2d065e4069568e78dcdc3318\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py\n",
            "Successfully installed box2d-py-2.3.5 swig-4.3.1.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "!pip install ale-py\n",
        "!apt-get install -y swig\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "BrsNHNQqVZLK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho_25-9_9qnu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n",
        "import torch.distributions as distributions\n",
        "from torch.distributions import Categorical\n",
        "import ale_py\n",
        "import gymnasium as gym\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium import ObservationWrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Building the AI"
      ],
      "metadata": {
        "id": "VF6EFSGUVlk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the architecture of the Neural Network"
      ],
      "metadata": {
        "id": "qyNc8cxbZCYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __inint__(self, action_size):\n",
        "    super(Network, self).__init__()\n",
        "    # Convolution layer\n",
        "    self.conv1 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=(3, 3), stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=2)\n",
        "    # Flatten layer\n",
        "    self.flatten = nn.Flatten()\n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(in_features=512, out_features=128)\n",
        "    self.fc2a = nn.Linear(in_features=128, out_features=action_size)\n",
        "    self.fc2b = nn.Linear(in_features=128, out_features=1)\n",
        "\n",
        "  def forward(self, state):\n",
        "    x = self.conv1(state)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.flatter(x)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    action_values = self.fc2a(x)\n",
        "    state_value = self.fc2b(x)[0]\n",
        "\n",
        "    return action_values, state_value\n",
        "\n"
      ],
      "metadata": {
        "id": "ZnysomZfOOFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Training the AI"
      ],
      "metadata": {
        "id": "eF5bETqbZbCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the environment"
      ],
      "metadata": {
        "id": "3C2ydyKLZgaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PreprocessAtari(ObservationWrapper):\n",
        "\n",
        "  def __init__(self, env, height = 42, width = 42, crop = lambda img: img, dim_order = 'pytorch', color = False, n_frames = 4):\n",
        "    super(PreprocessAtari, self).__init__(env)\n",
        "    self.img_size = (height, width)\n",
        "    self.crop = crop\n",
        "    self.dim_order = dim_order\n",
        "    self.color = color\n",
        "    self.frame_stack = n_frames\n",
        "    n_channels = 3 * n_frames if color else n_frames\n",
        "    obs_shape = {'tensorflow': (height, width, n_channels), 'pytorch': (n_channels, height, width)}[dim_order]\n",
        "    self.observation_space = Box(0.0, 1.0, obs_shape)\n",
        "    self.frames = np.zeros(obs_shape, dtype = np.float32)\n",
        "\n",
        "  def reset(self):\n",
        "    self.frames = np.zeros_like(self.frames)\n",
        "    obs, info = self.env.reset()\n",
        "    self.update_buffer(obs)\n",
        "    return self.frames, info\n",
        "\n",
        "  def observation(self, img):\n",
        "    img = self.crop(img)\n",
        "    img = cv2.resize(img, self.img_size)\n",
        "    if not self.color:\n",
        "      if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = img.astype('float32') / 255.\n",
        "    if self.color:\n",
        "      self.frames = np.roll(self.frames, shift = -3, axis = 0)\n",
        "    else:\n",
        "      self.frames = np.roll(self.frames, shift = -1, axis = 0)\n",
        "    if self.color:\n",
        "      self.frames[-3:] = img\n",
        "    else:\n",
        "      self.frames[-1] = img\n",
        "    return self.frames\n",
        "\n",
        "  def update_buffer(self, obs):\n",
        "    self.frames = self.observation(obs)\n",
        "\n",
        "def make_env():\n",
        "  env = gym.make('KungFuMasterNoFrameskip-v0', render_mode = 'rgb_array') # The KungFuMaster environment was renamed 'KungFuMasterNoFrameskip-v0'\n",
        "  env = PreprocessAtari(env, height = 42, width = 42, crop = lambda img: img, dim_order = 'pytorch', color = False, n_frames = 4)\n",
        "  return env\n",
        "\n",
        "env = make_env()\n",
        "\n",
        "state_shape = env.observation_space.shape\n",
        "number_actions = env.action_space.n\n",
        "print(\"State shape:\", state_shape)\n",
        "print(\"Number actions:\", number_actions)\n",
        "print(\"Action names:\", env.env.env.env.get_action_meanings())"
      ],
      "metadata": {
        "id": "gF756uIhRVcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b93f10d-9d3f-4e7a-8efa-99f7b4d293fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State shape: (4, 42, 42)\n",
            "Number actions: 14\n",
            "Action names: ['NOOP', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment KungFuMasterNoFrameskip-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the hyperparameters"
      ],
      "metadata": {
        "id": "YgRlooBmC1hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "discount_factor = 0.99\n",
        "number_environments = 10"
      ],
      "metadata": {
        "id": "1-Ww7pHB-AH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the A3C class"
      ],
      "metadata": {
        "id": "Gg_LmSs9IoTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self, action_size):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.action_size = action_size\n",
        "    self.network = Network(action_size).to(self.device)\n",
        "    self.optimizer = optim.Adam(self.network.parameters(), lr = learning_rate)\n",
        "\n",
        "  def act(self, state):\n",
        "    # check each frames\n",
        "    # Do not use unsqueeze since state is not a torch tensor\n",
        "    if state.ndim == 3:\n",
        "      state = [state]\n",
        "    state = torch.tensor(state, dtype = torch.float32, device = self.device)\n",
        "    # Call the forward method in the network\n",
        "    action_values, _ = self.network(state)\n",
        "    # Apply softmax to determine best outcome\n",
        "    policy = F.softmax(action_values, dim = 1)\n",
        "    return np.array([np.random.choice(len(p), p=p) for p in policy.detach().cpu().numpy()])\n",
        "\n",
        "  def step(self, state, action, reward, next_state, done):\n",
        "    batch_size = state.shape[0]\n",
        "    state = torch.tensor(state, dtype = torch.float32, device = self.device)\n",
        "    next_state = torch.tensor(next_state, dtype = torch.float32, device = self.device)\n",
        "    reward = torch.tensor(reward, dtype = torch.float32, device = self.device)\n",
        "    done = torch.tensor(next_state, dtype = torch.bool, device = self.device).to(dtype = torch.float32)\n",
        "    # Get action and state values\n",
        "    action_values, state_values = self.network(state)\n",
        "    next_action_values, next_state_values = self.network(next_state)\n",
        "    # Use bellmans equation\n",
        "    target_state_values = reward + discount_factor * next_state_values * (1 - done)\n",
        "\n",
        "    # Calulate the A3C parameters\n",
        "    advantage = target_state_values - state_values\n",
        "    probs = F.softmax(action_values, dim = -1)\n",
        "    logprobs = F.log_softmax(action_values, dim = -1)\n",
        "    entropy = -torch.sum(probs * logprobs, axis = -1)\n",
        "    batch_idx = np.arange(batch_size)\n",
        "    logp_actions = logprobs[batch_idx, action]\n",
        "    actor_loss = -(logp_actions * advantage.detach()).mean() - 0.001 * entropy.mean()\n",
        "    critic_loss = F.mse_loss(target_state_values.detach(), state_values)\n",
        "    total_loss = actor_loss + critic_loss\n",
        "    # Rest optimiser\n",
        "    self.optimizer.zero_grad()\n",
        "    # Backward propergation\n",
        "    total_loss.backward()\n",
        "    # update the weights to minimise total loss\n",
        "    self.optimizer.step()\n"
      ],
      "metadata": {
        "id": "c6a7Amp-ElmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the A3C agent"
      ],
      "metadata": {
        "id": "7RnRukHDKFJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating our A3C agent on a single episode"
      ],
      "metadata": {
        "id": "oB5SpmoKP0aK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing multiple agents on multiple environments at the same time"
      ],
      "metadata": {
        "id": "jVSqiyjiQeMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the A3C agent"
      ],
      "metadata": {
        "id": "69WZWB4oRx1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Visualizing the results"
      ],
      "metadata": {
        "id": "7kG_YR9YdmUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import imageio\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def show_video_of_model(agent, env):\n",
        "  state, _ = env.reset()\n",
        "  done = False\n",
        "  frames = []\n",
        "  while not done:\n",
        "    frame = env.render()\n",
        "    frames.append(frame)\n",
        "    action = agent.act(state)\n",
        "    state, reward, done, _, _ = env.step(action[0])\n",
        "  env.close()\n",
        "  imageio.mimsave('video.mp4', frames, fps=30)\n",
        "\n",
        "show_video_of_model(agent, env)\n",
        "\n",
        "def show_video():\n",
        "    mp4list = glob.glob('*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")\n",
        "\n",
        "show_video()"
      ],
      "metadata": {
        "id": "UGkTuO6DxZ6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}